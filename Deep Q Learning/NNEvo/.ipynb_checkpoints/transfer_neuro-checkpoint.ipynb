{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (3, 3, 512, 512) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8ffc3a36cdb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[0magents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNNEvo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m \u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_population\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Population created'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-8ffc3a36cdb8>\u001b[0m in \u001b[0;36mcreate_population\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransfer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_transfer_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-8ffc3a36cdb8>\u001b[0m in \u001b[0;36mcreate_transfer_cnn\u001b[1;34m(self, ref_model, y_dim, x_dim, rgb, fcn_weights)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mref_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m       \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras_applications\\resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                 md5_hash='a268eb855778b3df3c7506639542a6af')\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'theano'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mkeras_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_all_kernels_in_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m    160\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[0;32m    161\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m   1422\u001b[0m         \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m         \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[0mweight_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_attributes_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weight_names'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m     \u001b[0mweight_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweight_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweight_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m     \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[0msymbolic_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_legacy_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[0mweight_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_attributes_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weight_names'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m     \u001b[0mweight_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweight_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweight_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m     \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[0msymbolic_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_legacy_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[0myou\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mto\u001b[0m \u001b[0mread\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mwhole\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0mevery\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mcalled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \"\"\"\n\u001b[1;32m--> 766\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[1;31m# Special case for (0,)*-shape datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (3, 3, 512, 512) and data type float32"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Wednesday November 11, 2019\n",
    "\n",
    "@author: Blake Richey\n",
    "\n",
    "Implementation of NeuroEvolution Algorithm:\n",
    "  Develop a neurel network and implement genetic algorithm that finds optimum\n",
    "  weights, as an alternative to backpropogation\n",
    "'''\n",
    "\n",
    "import gym, operator\n",
    "import os, datetime, random\n",
    "import numpy             as np\n",
    "import tensorflow        as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from   time                          import time\n",
    "from   tensorflow.keras.optimizers   import Adam\n",
    "from   collections                   import deque\n",
    "from   tensorflow.keras              import backend\n",
    "from   sklearn.model_selection       import train_test_split\n",
    "from   tensorflow.keras.applications import ResNet50\n",
    "from   tensorflow.python.client      import device_lib\n",
    "from   tensorflow.keras.models       import Sequential, Model\n",
    "from   tensorflow.keras.callbacks    import TensorBoard, ModelCheckpoint\n",
    "from   tensorflow.keras.layers       import Dense, Dropout, Conv2D, MaxPooling2D, \\\n",
    "    Activation, Flatten, BatchNormalization, LSTM\n",
    "\n",
    "\n",
    "class NNEvo:\n",
    "\n",
    "  def __init__(self, \n",
    "    tour=3, \n",
    "    cxrt=.2,\n",
    "    mxrt=.01, \n",
    "    layers=1, \n",
    "    env=None,\n",
    "    elitist=3,\n",
    "    sharpness=1, \n",
    "    cxtype='avg',\n",
    "    population=10, \n",
    "    transfer=False,\n",
    "    generations=10, \n",
    "    selection='tour',\n",
    "    fitness_goal=200,\n",
    "    validation_size=0,\n",
    "    activation='linear', \n",
    "    nodes_per_layer=[4]):\n",
    "\n",
    "    '''\n",
    "      config = {\n",
    "        'tour': 3, \n",
    "        'cxrt': .2,\n",
    "        'mxrt': .01,\n",
    "        'layers': 1, \n",
    "        'env': None, \n",
    "        'elitist': 3,\n",
    "        'sharpness': 1,\n",
    "        'cxtype': 'avg',\n",
    "        'population': 10, \n",
    "        'generations': 10, \n",
    "        'transfer': False,\n",
    "        'selection': 'tour',\n",
    "        'fitness_goal': 200,\n",
    "        'validation_size': 0,\n",
    "        'activation': 'linear', \n",
    "        'nodes_per_layer': [4], \n",
    "      }\n",
    "    '''\n",
    "\n",
    "    self.default_nodes   = 20\n",
    "    self.env             = env\n",
    "    self.mxrt            = mxrt        #chance of a single weight being mutated\n",
    "    self.cxrt            = cxrt        #chance of parent being selected (crossover rate)\n",
    "    self.best_fit        = None        #(model, fitness) with best fitness\n",
    "    self.tour            = tour        #tournament sample size when using tour selection policy\n",
    "    self.cxtype          = cxtype      #cross over type (gene splicing or avging)\n",
    "    self.goal_met        = False       #holds model number that meets fitness goal\n",
    "    self.num_layers      = layers      #qty of hidden layers\n",
    "    self.elitist         = elitist     #n best models transitioned into nxt gen\n",
    "    self.transfer        = transfer\n",
    "    self.sharpness       = sharpness   #epochs to run when evaluating fitness\n",
    "    self.selection_type  = selection   #selection type (cxrt/tour)\n",
    "    self.activation      = activation  #activation type for output layer\n",
    "    self.pop_size        = population  #number of neural nets in population\n",
    "    self.generations     = generations \n",
    "    self.fitness_goal    = fitness_goal #goal for fitness (episode score) to reach\n",
    "    self.validation_size = validation_size #number of episodes to run to validate a models success in reaching a fitness goal\n",
    "    self.nodes_per_layer = nodes_per_layer #list of qty of nodes in each hidden layer\n",
    "    self.num_features    = self.env.observation_space.shape[0]\n",
    "    \n",
    "    outputs = 1\n",
    "    if hasattr(env.action_space, 'n'):\n",
    "      outputs = self.env.action_space.n\n",
    "    self.num_outputs     = outputs\n",
    "\n",
    "    self.models = [] #list of individuals \n",
    "    self.pop    = [] #population (2d-list of weights)\n",
    "    self.weight_shapes   = None\n",
    "    self.weights_lengths = None\n",
    "    self.plots = [] #points for matplotlib\n",
    "    self.episodes = 0\n",
    "    \n",
    "\n",
    "  #--- Initialize Population --------------------------------------------------+\n",
    "  def create_nn(self):\n",
    "    '''Create individual of population'''\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(self.num_features, input_shape = (self.num_features,)))\n",
    "    \n",
    "    for layer in range(self.num_layers):\n",
    "\n",
    "        try:\n",
    "            nodes=self.nodes_per_layer[layer]\n",
    "        except IndexError:\n",
    "            nodes = None\n",
    "\n",
    "        if nodes is None:\n",
    "            nodes = self.default_nodes\n",
    "\n",
    "        model.add(Dense(units = nodes, activation = 'relu'))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(units = self.num_outputs, activation = self.activation))\n",
    "    model.compile(optimizer = Adam(lr=0.001), loss = 'mse', metrics=['accuracy'])\n",
    "\n",
    "    #create deserialize dependencies\n",
    "    if self.weight_shapes is None:\n",
    "      model.summary()\n",
    "      self.weight_shapes = []\n",
    "      self.weights_lengths = []\n",
    "\n",
    "      weights = model.get_weights()\n",
    "      for x in weights:\n",
    "        self.weight_shapes.append(x.shape)\n",
    "\n",
    "        #generate indicies of weights to recreate weight structure from gene string\n",
    "        length = len(x.reshape(1, -1)[0].tolist())\n",
    "        if not self.weights_lengths:\n",
    "          self.weights_lengths.append(length)\n",
    "        else:\n",
    "          self.weights_lengths.append(self.weights_lengths[len(self.weights_lengths)-1]+length)\n",
    "      if self.mxrt is 1:\n",
    "        self.mxrt = 1/( self.weights_lengths[-1] * 1.8 )\n",
    "      print('Weight Lengths:', self.weights_lengths)\n",
    "      print('Mutation Rate:', self.mxrt)\n",
    "      print('Crossover Type:', self.cxtype)\n",
    "      print('Selection Type:', self.selection_type)\n",
    "      print('Sharpness:', self.sharpness)\n",
    "    return model\n",
    "  \n",
    "  def create_transfer_cnn(self, ref_model=None, y_dim=192, x_dim=192, rgb=3, fcn_weights=None):\n",
    "    '''creates resnet model. will load deserialized weights by passing in weights'''\n",
    "\n",
    "    if not ref_model:\n",
    "      model = ResNet50(weights='imagenet', include_top=False, input_shape=(y_dim, x_dim, rgb))\n",
    "      for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "      \n",
    "      pretrained_weights = model.get_weights()\n",
    "\n",
    "      flattened = Flatten()(model.output)\n",
    "      #Add FCN\n",
    "      for layer in range(self.num_layers):\n",
    "\n",
    "        try:\n",
    "            nodes=self.nodes_per_layer[layer]\n",
    "        except IndexError:\n",
    "            nodes = None\n",
    "\n",
    "        if nodes is None:\n",
    "            nodes = self.default_nodes\n",
    "\n",
    "        if layer == 0:\n",
    "          add_layer = Dense(units = nodes, activation = 'relu')(flattened)\n",
    "        else:\n",
    "          add_layer = Dense(units = nodes, activation = 'relu')(add_layer)\n",
    "      \n",
    "      output = Dense(units = self.num_outputs, activation = self.activation)(add_layer)\n",
    "\n",
    "      model = Model(model.inputs, output)\n",
    "      model.compile(Adam(lr=1e-3), 'categorical_crossentropy', metrics=['acc'])\n",
    "    else:\n",
    "      model = ref_model\n",
    "\n",
    "      if fcn_weights:\n",
    "        weights = model.get_weights()[-len(self.weight_shapes):]\n",
    "        print('Deserialized weights length:', len(weights))\n",
    "        for i, matrix in enumerate(weights):\n",
    "          print('Original', matrix)\n",
    "          matrix[:] = fcn_weights[i]\n",
    "          print('Result', matrix)\n",
    "    \n",
    "    #create deserialize dependencies\n",
    "    if self.weight_shapes is None:\n",
    "      model.summary()\n",
    "      self.weight_shapes = []\n",
    "      self.weights_lengths = []\n",
    "\n",
    "      weights = model.get_weights()\n",
    "      self.full_weights_length = len(weights)\n",
    "      self.pretrained_weights_length = len(pretrained_weights)\n",
    "      for i in range(len(pretrained_weights), len(weights)):\n",
    "        self.weight_shapes.append(weights[i].shape)\n",
    "\n",
    "        #generate indicies of weights to recreate weight structure from gene string\n",
    "        length = len(weights[i].reshape(1, -1)[0].tolist())\n",
    "        if not self.weights_lengths:\n",
    "          self.weights_lengths.append(length)\n",
    "        else:\n",
    "          self.weights_lengths.append(self.weights_lengths[len(self.weights_lengths)-1]+length)\n",
    "      if self.mxrt is 1:\n",
    "        self.mxrt = 1/( self.weights_lengths[-1] * 1.8 )\n",
    "      print('Weight Shapes:', self.weight_shapes)\n",
    "      print('Weight Lengths:', self.weights_lengths)\n",
    "      print('Mutation Rate:', self.mxrt)\n",
    "      print('Crossover Type:', self.cxtype)\n",
    "      print('Selection Type:', self.selection_type)\n",
    "      print('Sharpness:', self.sharpness)\n",
    "    \n",
    "    return model\n",
    "  \n",
    "  def create_population(self):\n",
    "    for _ in range(self.pop_size):\n",
    "      if self.transfer:\n",
    "        model = self.create_transfer_cnn()\n",
    "      else:\n",
    "        model = self.create_nn()\n",
    "      self.models.append(model)\n",
    "      self.pop.append(self.serialize(model))\n",
    "  #----------------------------------------------------------------------------+\n",
    "\n",
    "  #--- Fitness Calculation ----------------------------------------------------+\n",
    "\n",
    "  def quality(self, model):\n",
    "    '''\n",
    "      fitness function. Returns quality of model\n",
    "      Runs 1 episode of environment\n",
    "    '''\n",
    "    total_rewards = []\n",
    "    for epoch in range(self.sharpness):\n",
    "      self.episodes += 1\n",
    "      done = False\n",
    "      rewards = []\n",
    "      envstate = self.env.reset()\n",
    "      while not done:\n",
    "        action = self.predict(model, envstate)\n",
    "        envstate, reward, done, info = self.env.step(action)\n",
    "        rewards.append(reward)\n",
    "      \n",
    "      total_rewards.append(sum(rewards))\n",
    "    \n",
    "    return sum(total_rewards)/len(total_rewards)\n",
    "  \n",
    "  #----------------------------------------------------------------------------+\n",
    "  \n",
    "  #--- Breed Population -------------------------------------------------------+\n",
    "  def selection(self):\n",
    "    '''\n",
    "      generate mating pool, tournament && elistist selection policy\n",
    "    '''\n",
    "    selection = []\n",
    "\n",
    "    ranked = [] #ranked models, best to worst\n",
    "    for i, model in enumerate(self.models):\n",
    "      fitness = self.quality(model)\n",
    "      ranked.append((i, fitness))\n",
    "      if self.fitness_goal is not None and fitness >= self.fitness_goal:\n",
    "        if self.validation_size:\n",
    "          valid = self.validate(self.models[i])\n",
    "        else:\n",
    "          valid = True\n",
    "        \n",
    "        if valid:\n",
    "          self.goal_met = self.models[i] #save model that met goal\n",
    "          self.best_fit = (i, fitness)\n",
    "          break\n",
    "\n",
    "    if not self.goal_met:  #if goal met prepare to terminate\n",
    "      ranked = sorted(ranked, key=operator.itemgetter(1), reverse=True)\n",
    "      print('Ranked:', ranked)\n",
    "      self.best_fit = ranked[0]\n",
    "\n",
    "      for i in range(self.elitist):\n",
    "        selection.append(ranked[i])\n",
    "\n",
    "      if self.selection_type == 'tour':\n",
    "        while len(selection) < self.pop_size:\n",
    "          tourny = random.sample(ranked, self.tour)\n",
    "          selection.append(max(tourny, key=lambda x:x[1]))\n",
    "\n",
    "      elif self.selection_type == 'cxrt':\n",
    "        while len(selection) < self.pop_size:\n",
    "          for model in ranked:\n",
    "            if random.random() < self.cxrt:\n",
    "              selection.append(model)\n",
    "            \n",
    "\n",
    "    self.plots.append(self.best_fit)\n",
    "    return selection\n",
    "\n",
    "  def crossover(self, parents):\n",
    "    children = [] #gene strings\n",
    "\n",
    "    #keep elites\n",
    "    for i in range(self.elitist):\n",
    "      index = parents[i][0]\n",
    "      children.append(self.pop[index])\n",
    "\n",
    "    parents = random.sample(parents, len(parents)) #randomize breeding pool\n",
    "\n",
    "    #breed rest\n",
    "    i = 0 #parent number, genes to get\n",
    "    while len(children) < self.pop_size:\n",
    "      parent1 = parents[i]\n",
    "      parent2 = parents[len(parents)-i-1]\n",
    "\n",
    "      parent1_genes = self.pop[parent1[0]]\n",
    "      parent2_genes = self.pop[parent2[0]]\n",
    "      if self.cxtype == 'splice':\n",
    "        if self.num_layers > 1:\n",
    "          genes = []\n",
    "          for index, len_ in enumerate(self.weights_lengths): #splice each layer\n",
    "            if index == 0:\n",
    "              range_ = (0, len_)\n",
    "            else:\n",
    "              range_ = (self.weights_lengths[index-1], len_)\n",
    "\n",
    "            #splice genes\n",
    "            start = range_[0]\n",
    "            end = range_[1]\n",
    "            geneA = random.randrange(start, end)\n",
    "            geneB = random.randrange(geneA, end+1)\n",
    "            geneA -= start\n",
    "            geneB -= start\n",
    "\n",
    "            genes.append(splice_list(parent1_genes[start:end], parent2_genes[start:end], geneA, geneB))\n",
    "          child = flatten(genes)\n",
    "        else:\n",
    "          geneA = random.randrange(0, len(parent1_genes))\n",
    "          geneB = random.randrange(geneA, len(parent1_genes)+1)\n",
    "\n",
    "          child = splice_list(parent1_genes, parent2_genes, geneA, geneB)\n",
    "      else:\n",
    "        child = ((np.array(parent1_genes) + np.array(parent2_genes)) / 2).tolist()\n",
    "      \n",
    "      children.append(child)\n",
    "      i+=1\n",
    "    \n",
    "    return children\n",
    "  \n",
    "  def mutate(self, population):\n",
    "    for ind, individual in enumerate(population):\n",
    "      for i, gene in enumerate(individual):\n",
    "        mxrt = self.mxrt\n",
    "#        if self.pop_size > 10:\n",
    "#          if ind == len(population) - 1: #Randomly initialize last child\n",
    "#            mxrt = 1\n",
    "        if random.random() < mxrt:\n",
    "          individual[i] = random.uniform(-1, 1)\n",
    "    \n",
    "    return population\n",
    "  #----------------------------------------------------------------------------+\n",
    "  \n",
    "  #--- Train/Evaluate ---------------------------------------------------------+\n",
    "\n",
    "  def train(self, filename=None):\n",
    "    self.create_population()\n",
    "    print('Population created', len(self.pop))\n",
    "\n",
    "    if filename:\n",
    "      self.models[0].load_weights(filename)\n",
    "      self.pop[0] = self.serialize(self.models[0])\n",
    "      print('Model loaded from', filename)\n",
    "\n",
    "    for i in range(self.generations):\n",
    "      print('\\nGeneration:', i+1, '/', self.generations)\n",
    "      parents = self.selection()\n",
    "      if not self.goal_met:\n",
    "        print('Goal not met. Parents selected.')\n",
    "        print('Best fit:', self.best_fit)\n",
    "        children = self.crossover(parents)\n",
    "        print('Breeding done.')\n",
    "        new_pop = self.mutate(children)\n",
    "        print('Mutations done.')\n",
    "        \n",
    "        print('New pop:', len(new_pop))\n",
    "        self.pop = new_pop\n",
    "        for i, individual in enumerate(new_pop):\n",
    "          self.models[i].set_weights(self.deserialize(individual))\n",
    "      else:\n",
    "        print(f'Goal met! Episodes: {self.episodes}')\n",
    "        self.goal_met.save_weights('best_model.h5')\n",
    "        print('Best results saved to best_model.h5')\n",
    "        break\n",
    "    \n",
    "    if not self.goal_met:\n",
    "      if self.best_fit:\n",
    "        self.models[self.best_fit[0]].save_weights('best_model.h5')\n",
    "        print('Best results saved to best_model.h5')\n",
    "\n",
    "\n",
    "  def evaluate(self, filename=None, epochs=0):\n",
    "    if self.goal_met or filename:\n",
    "      #load model\n",
    "      if filename:\n",
    "        model = self.create_nn()\n",
    "        model.load_weights(filename)\n",
    "        print(f'Weights loaded from {filename}')\n",
    "      else:\n",
    "        model = self.goal_met\n",
    "\n",
    "      epoch = 0\n",
    "      total_rewards = []\n",
    "      #display results\n",
    "      while (True, epoch<epochs)[epochs>0]:\n",
    "        done = False\n",
    "        rewards = []\n",
    "        envstate = self.env.reset()\n",
    "        while not done:\n",
    "          action = self.predict(model, envstate)\n",
    "          envstate, reward, done, info = self.env.step(action)\n",
    "          if not epochs:\n",
    "            self.env.render()\n",
    "          rewards.append(reward)\n",
    "\n",
    "        print('Reward:', sum(rewards))\n",
    "        total_rewards.append(sum(rewards))\n",
    "        rewards = []\n",
    "        epoch+=1\n",
    "      print('Epochs:', epoch, 'Average reward:', sum(total_rewards)/len(total_rewards))\n",
    "  #----------------------------------------------------------------------------+\n",
    "\n",
    "  #--- Validate Fitness -------------------------------------------------------+\n",
    "  def validate(self, model):\n",
    "    print('Validating Model...', end='')\n",
    "    \n",
    "    total_rewards = []\n",
    "    n_epochs = self.validation_size\n",
    "    #test results\n",
    "    for epoch in range(n_epochs):\n",
    "      done = False\n",
    "      rewards = []\n",
    "      envstate = self.env.reset()\n",
    "      while not done:\n",
    "        action = self.predict(model, envstate)\n",
    "        envstate, reward, done, info = self.env.step(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "      total_rewards.append(sum(rewards))\n",
    "    print(sum(total_rewards)/len(total_rewards))\n",
    "    return sum(total_rewards)/len(total_rewards) >= self.fitness_goal\n",
    "  #----------------------------------------------------------------------------+\n",
    "\n",
    "  #--- Graph Functions --------------------------------------------------------+\n",
    "\n",
    "  def show_plot(self):\n",
    "    y = [self.plots[i][1] for i in range(len(self.plots))] #best fitness\n",
    "    x = [i for i in range(len(self.plots))] #generation\n",
    "\n",
    "    plt.plot(x, y, label='Best fitness')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    \n",
    "  #----------------------------------------------------------------------------+\n",
    "\n",
    "  #--- Helper Functions -------------------------------------------------------+\n",
    "\n",
    "  def predict(self, model, envstate):\n",
    "    ''' decide best action for model. '''\n",
    "    qvals = model.predict(self.adj_envstate(envstate))[0] \n",
    "    if self.num_outputs == 1:\n",
    "      action = qvals #continuous action space\n",
    "    else:\n",
    "      action = np.argmax(qvals) #discrete action space\n",
    "    \n",
    "    return action\n",
    "\n",
    "  def adj_envstate(self, envstate):\n",
    "    return envstate.reshape(1, -1)\n",
    "\n",
    "  def serialize(self, model):\n",
    "    '''\n",
    "      serializes model's weights into a gene string\n",
    "    '''\n",
    "    \n",
    "    if self.transfer:\n",
    "        weights = model.get_weights()[-len(self.weight_shapes):]\n",
    "    else:\n",
    "        weights = model.get_weights()\n",
    "    flattened = []\n",
    "    for arr in weights:\n",
    "      flattened+=arr.reshape(1, -1)[0].tolist()\n",
    "    \n",
    "    return flattened\n",
    "\n",
    "  def deserialize(self, genes):\n",
    "    '''\n",
    "      deserializes gene string into weights\n",
    "    '''\n",
    "    shapes = self.weight_shapes\n",
    "    lengths = self.weights_lengths\n",
    "    \n",
    "    weights = []\n",
    "    for i, val in enumerate(lengths):\n",
    "      if i == 0:\n",
    "        begin = 0\n",
    "      else:\n",
    "        begin = lengths[i-1]\n",
    "      print(begin, val)\n",
    "      weights.append(np.array(genes[begin:val]).reshape(shapes[i]))\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def splice_list(list1, list2, index1, index2):\n",
    "  '''\n",
    "    combined list1 and list2 taking splice from list1 with starting index `index1`\n",
    "    and ending index `index2`\n",
    "  '''\n",
    "  if index1 == 0:\n",
    "    splice = list1[index1:index2+1]\n",
    "    splice += list2[index2+1:len(list1)]\n",
    "  else:\n",
    "    splice = list2[:index1] + list1[index1:index2+1]\n",
    "    splice += list2[index2+1:len(list1)]\n",
    "  \n",
    "  return splice\n",
    "\n",
    "def flatten(L):\n",
    "  'flatten 2d list'\n",
    "  flat = []\n",
    "  for l in L:\n",
    "    flat += l\n",
    "  \n",
    "  return flat\n",
    "#------------------------------------------------------------------------------+\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "print('Environment created')\n",
    "# print(hasattr(env.action_space, 'n'))\n",
    "\n",
    "config = {\n",
    "  'tour': 3, \n",
    "  'cxrt': .2,\n",
    "  'mxrt': .01,\n",
    "  'layers': 4, \n",
    "  'env': env, \n",
    "  'elitist': 3,\n",
    "  'sharpness': 1,\n",
    "  'cxtype': 'avg',\n",
    "  'population': 10, \n",
    "  'generations': 10, \n",
    "  'transfer': True,\n",
    "  'selection': 'tour',\n",
    "  'fitness_goal': 200,\n",
    "  'validation_size': 0,\n",
    "  'activation': 'softmax', \n",
    "  'nodes_per_layer': [2, 64, 32, 3], \n",
    "}\n",
    "\n",
    "agents = NNEvo(**config)\n",
    "agents.create_population()\n",
    "print('Population created')\n",
    "\n",
    "\n",
    "# start = time()\n",
    "# train()\n",
    "# end = time()\n",
    "# print('Time training:', end-start)\n",
    "# evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 23737549 into shape (73728,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9e92d83123f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_pop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'New pop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnew_pop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_pop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Deserialized weights'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_pop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_transfer_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcn_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_pop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-8ffc3a36cdb8>\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(self, genes)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0mbegin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m       \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 23737549 into shape (73728,2)"
     ]
    }
   ],
   "source": [
    "agents.mxrt = .5\n",
    "prior = agents.pop[0]\n",
    "new_pop = agents.mutate([agents.pop[0]])\n",
    "print('New pop', prior == new_pop, prior[-150:], new_pop[-150:])\n",
    "print('Deserialized weights', (agents.deserialize(new_pop))[2:])\n",
    "agents.create_transfer_cnn(ref_model=agents.models[0], fcn_weights=agents.deserialize(new_pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(73728, 2), (2,), (2, 64), (64,), (64, 32), (32,), (32, 3), (3,), (3, 2), (2,)]\n",
      "[147456, 147458, 147586, 147650, 149698, 149730, 149826, 149829, 149835, 149837]\n"
     ]
    }
   ],
   "source": [
    "print(agents.weight_shapes)\n",
    "print(agents.weights_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def deserialize(self, genes):\n",
    "    '''\n",
    "      deserializes gene string into weights\n",
    "    '''\n",
    "    shapes = self.weight_shapes\n",
    "    lengths = self.weights_lengths\n",
    "    \n",
    "    weights = []\n",
    "    for i, val in enumerate(lengths):\n",
    "      if i == 0:\n",
    "        begin = 0\n",
    "      else:\n",
    "        begin = lengths[i-1]\n",
    "      weights.append(np.array(genes[begin:val]).reshape(shapes[i]))\n",
    "    \n",
    "    return weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
